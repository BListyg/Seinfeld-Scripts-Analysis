ggplot(aes(x = word, y = tf_idf, fill = Season)) +
geom_col(show.legend = F) +
facet_wrap(~Season, ncol = 2, scales = "free") +
labs(x = NULL, y = "tf-idf") +
coord_flip() +
theme_bw()
plot_seinfeld %>%
ungroup() %>%
mutate(word = reorder(word, tf_idf)) %>%
ggplot(aes(x = word, y = tf_idf, fill = Season)) +
geom_col(show.legend = F) +
facet_wrap(~Season, ncol = 2, scales = "free") +
labs(x = NULL, y = "tf-idf") +
coord_flip() +
theme_light()
tidy_scripts %>%
inner_join(get_sentiments(scoring_sentiment)) %>%
count(word, sentiment, sort = T) %>%
ungroup() %>%
group_by(sentiment) %>%
filter(word != "funny") %>%
top_n(10) %>%
ungroup() %>%
mutate(word = reorder(word, n)) %>%
ggplot() +
geom_col(aes(x = word, y = n, fill = sentiment), show.legend = F) +
facet_wrap(~sentiment, scales = "free_y") +
labs(x = "Word", y = "Contribution to sentiment") +
coord_flip() +
theme_light()
plot_seinfeld %>%
ungroup() %>%
mutate(word = reorder(word, tf_idf)) %>%
ggplot(aes(x = word, y = tf_idf, fill = Season)) +
geom_col(show.legend = F) +
facet_grid(~Season, ncol = 2, nrow = 5, scales = "free") +
labs(x = NULL, y = "tf-idf") +
coord_flip() +
theme_light()
plot_seinfeld %>%
ungroup() %>%
mutate(word = reorder(word, tf_idf)) %>%
ggplot(aes(x = word, y = tf_idf, fill = Season)) +
geom_col(show.legend = F) +
facet_grid(~Season, scales = "free") +
labs(x = NULL, y = "tf-idf") +
coord_flip() +
theme_light()
ra
plot_seinfeld <-  seinfeld_words %>%
arrange(desc(tf_idf)) %>%
mutate(word = factor(word, levels = rev(unique(word)))) %>%
group_by(Season) %>%
top_n(10, tf_idf)
plot_seinfeld %>%
ungroup() %>%
mutate(word = reorder(word, tf_idf)) %>%
ggplot(aes(x = word, y = tf_idf, fill = Season)) +
geom_col(show.legend = F) +
facet_wrap(~Season, ncol = 2, scales = "free") +
labs(x = NULL, y = "tf-idf") +
coord_flip() +
theme_light()
plot_seinfeld <-  seinfeld_words %>%
arrange(desc(tf_idf)) %>%
mutate(word = factor(word, levels = rev(unique(word)))) %>%
group_by(Season) %>%
top_n(10, tf_idf)
plot_seinfeld %>%
ungroup() %>%
mutate(word = reorder(word, tf_idf)) %>%
ggplot(aes(x = word, y = tf_idf, fill = Season)) +
geom_col(show.legend = F) +
facet_wrap(~Season, ncol = 1, scales = "free") +
labs(x = NULL, y = "tf-idf") +
coord_flip() +
theme_light()
plot_seinfeld <-  seinfeld_words %>%
arrange(desc(tf_idf)) %>%
mutate(word = factor(word, levels = rev(unique(word)))) %>%
group_by(Season) %>%
top_n(10, tf_idf)
plot_seinfeld %>%
ungroup() %>%
mutate(word = reorder(word, tf_idf)) %>%
ggplot(aes(x = word, y = tf_idf, fill = Season)) +
geom_col(show.legend = F) +
facet_wrap(~Season, ncol = 1, scales = "free_y") +
labs(x = NULL, y = "tf-idf") +
coord_flip() +
theme_light()
plot_seinfeld %>%
ungroup() %>%
mutate(word = reorder(word, tf_idf)) %>%
ggplot(aes(x = word, y = tf_idf, fill = Season)) +
geom_col(show.legend = F) +
facet_wrap(~Season, ncol = 4, scales = "free_y") +
labs(x = NULL, y = "tf-idf") +
coord_flip() +
theme_light()
plot_seinfeld %>%
ungroup() %>%
mutate(word = reorder(word, tf_idf)) %>%
ggplot(aes(x = word, y = tf_idf, fill = Season)) +
geom_col(show.legend = F) +
facet_wrap(~Season, ncol = 4, scales = "free") +
labs(x = NULL, y = "tf-idf") +
coord_flip() +
theme_light()
scripts %>%
unnest(bigram, Dialogue, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word2 %in% stop_words$word) %>%
count(word1, word2, sort = T)
scripts %>%
unnest_tokens(bigram, Dialogue, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word2 %in% stop_words$word) %>%
count(word1, word2, sort = T)
bigrams_separated <- scripts %>%
unnest_tokens(bigram, Dialogue, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word2 %in% stop_words$word) %>%
count(word1, word2, sort = T)
bigrams_separated <- scripts %>%
unnest_tokens(bigram, Dialogue, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word2 %in% stop_words$word)
get_sentiments(scoring_sentiment)
bigrams_separated <- scripts %>%
unnest_tokens(bigram, Dialogue, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word2 %in% stop_words$word)
not_words <- bigrams_separated %>%
filter(word1 == "not") %>%
inner_join(get_sentiments(scoring_sentiment)) %>%
count(word2, sentiment, sort = T) %>%
ungroup()
not_words <- bigrams_separated %>%
filter(word1 == "not") %>%
inner_join(get_sentiments(scoring_sentiment), by = (word2 = "word")) %>%
count(word2, sentiment, sort = T) %>%
ungroup()
get_sentiments(scoring_sentiment)
bing <- get_sentiments("bing")
bigrams_separated <- scripts %>%
unnest_tokens(bigram, Dialogue, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word2 %in% stop_words$word)
bing <- get_sentiments("bing")
not_words <- bigrams_separated %>%
filter(word1 == "not") %>%
inner_join(bing, by = c(word2 = "word")) %>%
count(word2, sentiment, sort = T) %>%
ungroup()
not_words
get_sentiments(scoring_sentiment)
not_words <- bigrams_separated %>%
filter(word1 == "not") %>%
inner_join(get_sentiments(scoring_sentiment), by = c(word2 = "word")) %>%
count(word2, sentiment, sort = T) %>%
ungroup()
not_words <- bigrams_separated %>%
filter(word1 == "not") %>%
inner_join(get_sentiments(scoring_sentiment), by = c(word2 = "word")) %>%
count(word2, sentiment, sort = T) %>%
ungroup()
not_words
not_words <- bigrams_separated %>%
filter(word1 == "not") %>%
inner_join(get_sentiments(scoring_sentiment), by = c(word2 = "word"))
not_words
not_words <- bigrams_separated %>%
filter(word1 == "not")
not_words
bigrams_separated <- scripts %>%
unnest_tokens(bigram, Dialogue, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word2 %in% stop_words$word)
# bing <- get_sentiments("bing")
not_words <- bigrams_separated %>%
filter(word1 == "not")
not_words
get_sentiments(scoring_sentiment)
bigrams_separated <- scripts %>%
unnest_tokens(bigram, Dialogue, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ")
bigrams_filtered <- bigrams_separated %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word2 %in% stop_words$word)
# bing <- get_sentiments("bing")
not_words <- bigrams_separated %>%
filter(word1 == "not")
not_words
get_sentiments(scoring_sentiment)
not_words <- bigrams_separated %>%
filter(word1 == "not") %>%
inner_join(get_sentiments(scoring_sentiment), by = c(word2 = "word")) %>%
count(word2, sentiment, sort = T) %>%
ungroup()
not_words
bigrams_separated <- scripts %>%
unnest_tokens(bigram, Dialogue, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ")
bigrams_filtered <- bigrams_separated %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word2 %in% stop_words$word)
# bing <- get_sentiments("bing")
not_words <- bigrams_separated %>%
filter(word1 == "not") %>%
inner_join(get_sentiments("AFINN"), by = c(word2 = "word")) %>%
count(word2, sentiment, sort = T) %>%
ungroup()
bigrams_separated <- scripts %>%
unnest_tokens(bigram, Dialogue, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ")
bigrams_filtered <- bigrams_separated %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word2 %in% stop_words$word)
# bing <- get_sentiments("bing")
not_words <- bigrams_separated %>%
filter(word1 == "not") %>%
inner_join(get_sentiments("AFINN"), by = c(word2 = "word")) %>%
count(word2, score, sort = T) %>%
ungroup()
not_words <- bigrams_separated %>%
filter(word1 == "not") %>%
inner_join(get_sentiments("afinn"), by = c(word2 = "word")) %>%
count(word2, score, sort = T) %>%
ungroup()
not_words
not_words %>%
mutate(contibution = n * score) %>%
arrange(desc(abs(contribution))) %>%
head(20) %>%
mutate(word2 = reorder(word2, contribution)) %>%
ggplot() +
geom_col(aes(x = word2, y = contribution, fill = (n * score > 0)), show.legend = F) +
labs(x = "Words preceeded by \"not\"", y = "Sentiment score * number of occurences") +
coord_flip()
not_words %>%
mutate(contribution = n * score) %>%
arrange(desc(abs(contribution))) %>%
head(20) %>%
mutate(word2 = reorder(word2, contribution)) %>%
ggplot() +
geom_col(aes(x = word2, y = contribution, fill = (n * score > 0)), show.legend = F) +
labs(x = "Words preceeded by \"not\"", y = "Sentiment score * number of occurences") +
coord_flip()
bigrams_united <- bigrams_separated %>%
unite(bigram, word1, word2, sep = " ")
bigrams_united <- bigrams_separated %>%
unite(bigram, word1, word2, sep = " ")
bigrams_tf_idf <- bigrams_united %>%
count(Season, bigram) %>%
bind_tf_idf(bigram, Season, n) %>%
arrange(desc(tf_idf))
bigrams_tf_idf
bigrams_tf_idf <- bigrams_united %>%
count(Season, bigram) %>%
bind_tf_idf(bigram, Season, n) %>%
arrange(desc(tf_idf)) %>%
mutate(bigram = factor(bigram, rev(unique(bigram)))) %>%
group_by(Season) %>%
top_n(10, tf_idf)
bigrams_tf_idf
bigrams_tf_idf %>%
ungroup() %>%
mutate(bigram = reorder(bigram, tf_idf)) %>%
ggplot() +
geom_col(aes(x = bigram, y = tf_idf, fill = Season), show.legend = F) +
facet_wrap(~Season, ncol = 4, scales = "free") +
labs(x = NULL, y = "tf-idf") +
coord_flip() +
theme_light()
knitr::opts_chunk$set(echo = TRUE)
setwd("/Users/kaimiddlebrook/Documents/s2-courses-2017-18/statistics-with-applications/data")
nike <- read_tsv("nike.txt")
library(tidyverse)
nike <- read_tsv("nike.txt")
setwd("/Users/kaimiddlebrook/Documents/s2-courses-2017-18/statistics-with-applications/data")
nike <- read_tsv("nike.txt")
setwd("/Users/kaimiddlebrook/Documents/s2-courses-2017-18/statistics-with-applications/data")
nike <- read_tsv("nike.txt")
setwd("/Users/kaimiddlebrook/Documents/s2-courses-2017-18/statistics-with-applications/data")
nike <- read_tsv("nike.txt")
n <- nrow(nike)
p <- 0.95
cp <- (1 + p)/2
t <- qt(cp, df = ((2*n) - 1))
xbar_1 <- mean(nike$AD1, na.rm = T)
xbar_2 <- mean(nike$AD2, na.rm = T)
sample_xbar <- xbar_1 - xbar_2
s1 <- var(nike$AD1)
s2 <- var(nike$AD2)
sample_var <- (((n-1) * s1) + (((n-1) * s2))) / ((2*n) - 2)
sample_sd <- sqrt(sample_var)
upper_B <- sample_xbar + (t * (sample_sd * sqrt(1/2*n)))
lower_B <- sample_xbar - (t * (sample_sd * sqrt(1/2*n)))
tu_theta <- xbar * (sqrt(pi/2))
Z <- qnorm(cp)
sd_denominator <- ((2*n) - 2)
sd_sqrt <- sqrt(Z/sd_denominator)
t <- qt(cp, df = ((2*n) - 2))
sd_sqrt <- sqrt(Z/sd_denominator)
upper_B <- sample_xbar + (t * sd_sqrt)
lower_B <- sample_xbar - (t * sd_sqrt)
sample_var <- (s1 + s2) / n
sample_sd <- sqrt(sample_var)
sample_sd <- sqrt(sample_var)
approx_lower_B <- sample_xbar + (t * sample_sd)
approx_upper_B <- sample_xbar - (t * sample_sd)
approx_upper_B <- sample_xbar + (t * sample_sd)
approx_lower_B <- sample_xbar - (t * sample_sd)
rm(list = ls())
cat('\014')
x <- rnorm(n, mean = 5, sd = 2)
?rnomr
?rnorm
rm(list = ls())
cat('\014')
sd <- 2
n <- 50
x <- rnorm(n, mean = 5, sd = 2)
xbar <- mean(x)
cp <- (1 + p)/2
p <- .60
cp <- (1 + p)/2
Z <- qnorm(cp)
lower_b <- xbar - (Z * (sd / sqrt(n)))
upper_B <- xbar + (Z * (sd / sqrt(n)))
x_samples <- rnorm(n, mean = 5, sd = 2)
rm(list = ls())
cat('\014')
sd <- 2
n <- 50
x <- rnorm(n, mean = 5, sd = 2)
xbar <- mean(x)
p <- .60
cp <- (1 + p)/2
Z <- qnorm(cp)
lower_b <- xbar - (Z * (sd / sqrt(n)))
upper_B <- xbar + (Z * (sd / sqrt(n)))
means <- c()
for(i in 1:100) {
x_samples <- rnorm(n, mean = 5, sd = 2)
means <- mean(x_samples)
}
x_samples <- c()
means <- c()
for(i in 1:100) {
x_samples[i] <- rnorm(n, mean = 5, sd = 2)
means[i] <- mean(x_samples[i])
}
upper_b <- xbar + (Z * (sd / sqrt(n)))
means %>%
filter(means <= upper_b && means >= lower_b)
means[means <= upper_b]
means[means <= upper_b && means >= lower_b]
means[means <= upper_b]
means[means <= upper_b & means >= lower_b]
means[means <= upper_b]
means[means >= lower_b]
means[means >= lower_b, means <= upper_b]
means[means >= lower_b | means <= upper_b]
means[means >= lower_b || means <= upper_b]
means[means >= lower_b & means <= upper_b]
rm(list = ls())
cat('\014')
sd <- 2
n <- 50
x <- rnorm(n, mean = 5, sd = 2)
xbar <- mean(x)
p <- .60
cp <- (1 + p)/2
Z <- qnorm(cp)
lower_b <- xbar - (Z * (sd / sqrt(n)))
upper_b <- xbar + (Z * (sd / sqrt(n)))
x_samples <- c()
means <- c()
for(i in 1:100) {
x_samples[i] <- rnorm(n, mean = 5, sd = 2)
means[i] <- mean(x_samples[i])
}
means[means >= lower_b & means <= upper_b]
means[means >= lower_b & means <= upper_b]
means_in_range <-  means[means >= lower_b & means <= upper_b]
num_in_range <- length(means_in_range)
num_in_bounds <- num_in_range / 100
setwd("/Users/kaimiddlebrook/Documents/s2-courses-2017-18/statistics-with-applications/data")
nike <- read_tsv("nike.txt")
n <- nrow(nike)
p <- 0.95
cp <- (1 + p)/2
t <- qt(cp, df = ((2*n) - 2))
xbar_1 <- mean(nike$AD1, na.rm = T)
xbar_2 <- mean(nike$AD2, na.rm = T)
sample_xbar <- xbar_1 - xbar_2
s1 <- var(nike$AD1)
s2 <- var(nike$AD2)
sample_var <- (s1 + s2) / n
sample_sd <- sqrt(sample_var)
Z <- qnorm(cp)
sd_denominator <- ((2*n) - 2)
approx_upper_B <- sample_xbar + (t * sample_sd)
approx_lower_B <- sample_xbar - (t * sample_sd)
sd_sqrt <- sqrt(Z/sd_denominator)
upper_B <- sample_xbar + (t * sd_sqrt)
lower_B <- sample_xbar - (t * sd_sqrt)
setwd("/Users/kaimiddlebrook/Documents/s2-courses-2017-18/statistics-with-applications/data")
nike <- read_tsv("nike.txt")
n <- nrow(nike)
p <- 0.95
cp <- (1 + p)/2
t <- qt(cp, df = ((2*n) - 2))
xbar_1 <- mean(nike$AD1, na.rm = T)
xbar_2 <- mean(nike$AD2, na.rm = T)
sample_xbar <- xbar_1 - xbar_2
s1 <- var(nike$AD1)
s2 <- var(nike$AD2)
sample_var <- (s1 + s2) / n
sample_sd <- sqrt(sample_var)
Z <- qnorm(cp)
sd_denominator <- ((2*n) - 2)
approx_upper_B <- sample_xbar + (t * sample_sd)
approx_lower_B <- sample_xbar - (t * sample_sd)
sd_sqrt <- sqrt(Z/sd_denominator)
upper_B <- sample_xbar + (t * sd_sqrt)
lower_B <- sample_xbar - (t * sd_sqrt)
setwd("/Users/kaimiddlebrook/Documents/s2-courses-2017-18/statistics-with-applications/data")
nike <- read_tsv("nike.txt")
n <- nrow(nike)
p <- 0.95
cp <- (1 + p)/2
t <- qt(cp, df = ((2*n) - 2))
xbar_1 <- mean(nike$AD1, na.rm = T)
xbar_2 <- mean(nike$AD2, na.rm = T)
(sample_xbar <- xbar_1 - xbar_2)
s1 <- var(nike$AD1)
s2 <- var(nike$AD2)
(sample_var <- (s1 + s2) / n)
(sample_sd <- sqrt(sample_var))
Z <- qnorm(cp)
sd_denominator <- ((2*n) - 2)
(approx_upper_B <- sample_xbar + (t * sample_sd))
(approx_lower_B <- sample_xbar - (t * sample_sd))
(sd_sqrt <- sqrt(Z/sd_denominator))
(upper_B <- sample_xbar + (t * sd_sqrt))
(lower_B <- sample_xbar - (t * sd_sqrt))
setwd("/Users/kaimiddlebrook/Documents/s2-courses-2017-18/statistics-with-applications/data")
nike <- read_tsv("nike.txt")
n <- nrow(nike)
p <- 0.95
cp <- (1 + p)/2
t <- qt(cp, df = ((2*n) - 2))
xbar_1 <- mean(nike$AD1, na.rm = T)
xbar_2 <- mean(nike$AD2, na.rm = T)
(sample_xbar <- xbar_1 - xbar_2)
s1 <- var(nike$AD1)
s2 <- var(nike$AD2)
(sample_var <- (s1 + s2) / n)
(sample_sd <- sqrt(sample_var))
Z <- qnorm(cp)
sd_denominator <- ((2*n) - 2)
(approx_upper_B <- sample_xbar + (t * sample_sd))
(approx_lower_B <- sample_xbar - (t * sample_sd))
(sd_sqrt <- sqrt(Z/sd_denominator))
(upper_B <- sample_xbar + (t * sd_sqrt))
(lower_B <- sample_xbar - (t * sd_sqrt))
rm(list = ls())
cat('\014')
sd <- 2
n <- 50
x <- rnorm(n, mean = 5, sd = 2)
(xbar <- mean(x))
p <- .60
cp <- (1 + p)/2
Z <- qnorm(cp)
(lower_b <- xbar - (Z * (sd / sqrt(n))))
(upper_b <- xbar + (Z * (sd / sqrt(n))))
x_samples <- c()
means <- c()
for(i in 1:100) {
x_samples[i] <- rnorm(n, mean = 5, sd = 2)
means[i] <- mean(x_samples[i])
}
means
rm(list = ls())
cat('\014')
sd <- 2
n <- 50
x <- rnorm(n, mean = 5, sd = 2)
(xbar <- mean(x))
p <- .60
cp <- (1 + p)/2
Z <- qnorm(cp)
(lower_b <- xbar - (Z * (sd / sqrt(n))))
(upper_b <- xbar + (Z * (sd / sqrt(n))))
means <- c()
for(i in 1:100) {
x_samples <- rnorm(n, mean = 5, sd = 2)
means[i] <- mean(x_samples)
}
means
means[means >= lower_b & means <= upper_b]
